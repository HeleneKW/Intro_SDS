{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hairy-disney",
   "metadata": {},
   "source": [
    "## Import the same libraries as in your first scraping notebook (just copy the \"import\" statements from the first notebook into this one and execute the cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-source",
   "metadata": {},
   "source": [
    "## Exercise 1: Count the number of characters in the titles and in the summaries, and investigate how they are related to rating and rating counts.\n",
    "\n",
    "1. Use [pd.read_csv](https://pandas.pydata.org/pandas-docs/dev/reference/api/pandas.read_csv.html) to load one of the dataframes, you stored in your first scraping notebook, into this notebook. This could be the \"carrots\" recipes or the recipes for the search term, you chose yourself.\n",
    "\n",
    "2. How do you count the number of characters in a single string, e.g. the number of characters in the string \"Counting characters is an essential human skill\"? Hint: See [this link](https://www.w3schools.com/python/ref_func_len.asp) about the \"len\" function. Does this function count black spaces? (You don't have to look for the answer in the documentation, you can just test it on your own). How many characters are there in the string \"Counting characters is an essential human skill\"?\n",
    "\n",
    "3. Now count the number of characters in each of the recipe titles. Use the function [pd.Series.apply](https://pandas.pydata.org/docs/reference/api/pandas.Series.apply.html) to apply the [len function](https://www.w3schools.com/python/ref_func_len.asp) to each of rows in the \"title\" column of your dataframe. (You could also use a for loop for this, but using the apply function is much better pandas coding practice, since it can really speed up your code, when the task is more complicated than counting characters.)\n",
    "\n",
    "4. Store the number of characters in the titles as a new column called \"title_len\" in the dataframe. If you don't know how to add a new column in a pandas dataframe, then try to google \"python pandas make new column\" or something similar, and see if you can find out on your own.\n",
    "\n",
    "5. Repeat step 3-4 with the summaries instead of the titles, so you end up with a column \"summary_len\", which counts the number of characters in the summaries.\n",
    "\n",
    "6. Use histograms to visualize the distributions of title_len and summary_len, and use scatterplots (or [regplot](https://seaborn.pydata.org/generated/seaborn.regplot.html)) to visualize the relationship between title_len, summary_len, rating and rating_count. What insights do you get?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-charge",
   "metadata": {},
   "source": [
    "## Exercise 2: Put recipes from different search terms into one big dataframe and compare the recipes\n",
    "\n",
    "Just so you know, you could also do the comparisons between recipes from different search terms without putting everything into one large dataframe (ant this would probably be easier in this particular case), but we are doing the \"one-big-dataframe\" as a coding exercise :)\n",
    "\n",
    "1. Copy the code, which defines the functions for scraping and formatting the scraped data, from the first notebook into this book. Execute the cell (this defines the functions in this notebook).\n",
    "\n",
    "2. Next, copy the code, which scrapes allrecipes.com for the recipes relating to a search term and stores the results in a dataframe. Make dataframes for some different search terms, which you find interesting to compare, e.g. \"beef\", \"pork\", \"chicken\" and \"meat\".\n",
    "\n",
    "3. In each of these dataframes, make a column \"search term\", which contains the search term you used to scrape the recipes.\n",
    "\n",
    "4. Use [pd.concat](https://pandas.pydata.org/docs/reference/api/pandas.concat.html) to make the dataframes into a single dataframe. This dataframe should contain all the rows of the other dataframes together. It should have the same columns as the dataframes in your first scraping notebook, and additionally a \"search term\" column, which states the search term, which gave rise to the recipe in the given row.\n",
    "\n",
    "5. If you are feeling advanced, you can try to use a [for loop](https://www.w3schools.com/python/python_for_loops.asp) to perform step 3-5 in a single for loop.\n",
    "\n",
    "6. Store this dataframe locally on computer.\n",
    "\n",
    "7. Use [pandas row selection](https://stackoverflow.com/questions/17071871/how-do-i-select-rows-from-a-dataframe-based-on-column-values) to select the rows, which belong to a specific search term.\n",
    "\n",
    "8. Use row selection combined with seaborn histograms to visualize the distribution of ratings and rating counts for the different search terms.\n",
    "\n",
    "9. Use [pd.groupby](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) combined with [pd.Series.mean](https://pandas.pydata.org/docs/reference/api/pandas.Series.mean.html) to calculate the average rating for each of the search terms. Use pd.groupby combined with [pd.Series.quantile](https://pandas.pydata.org/docs/reference/api/pandas.Series.quantile.html) to calculate various quantiles of the rating distributions for the different search terms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
